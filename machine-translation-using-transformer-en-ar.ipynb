{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11452194,"sourceType":"datasetVersion","datasetId":7175466},{"sourceId":11503258,"sourceType":"datasetVersion","datasetId":7212075}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:07:40.837828Z","iopub.execute_input":"2025-04-21T18:07:40.838098Z","iopub.status.idle":"2025-04-21T18:07:41.107678Z","shell.execute_reply.started":"2025-04-21T18:07:40.838078Z","shell.execute_reply":"2025-04-21T18:07:41.107105Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/d/bedomostafa/en-to-ar/ara_.txt\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# **Import Libraries**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport math\nimport copy\nimport numpy as np\nimport re\nimport requests\nfrom io import StringIO\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nfrom tabulate import tabulate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:07:41.108809Z","iopub.execute_input":"2025-04-21T18:07:41.109323Z","iopub.status.idle":"2025-04-21T18:07:42.747195Z","shell.execute_reply.started":"2025-04-21T18:07:41.109304Z","shell.execute_reply":"2025-04-21T18:07:42.746644Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# **Ensure Using GPU**","metadata":{}},{"cell_type":"code","source":"# Check if GPU is available\nif torch.cuda.is_available():\n    device = torch.device('cuda')\n    print(f\"Running on {torch.cuda.get_device_name(0)}\")\nelse:\n    device = torch.device('cpu')\n    print(\"Running on CPU\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:07:42.747828Z","iopub.execute_input":"2025-04-21T18:07:42.748107Z","iopub.status.idle":"2025-04-21T18:07:42.884212Z","shell.execute_reply.started":"2025-04-21T18:07:42.748089Z","shell.execute_reply":"2025-04-21T18:07:42.883532Z"}},"outputs":[{"name":"stdout","text":"Running on Tesla T4\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# **Load Dataset**","metadata":{}},{"cell_type":"code","source":"def load_data(filepath):\n    with open(filepath, 'r', encoding='utf-8') as f:\n        lines = f.readlines()\n\n    english_sentences = []\n    arabic_sentences = []\n\n    for line in lines:\n        parts = line.strip().split('\\t')\n        if len(parts) >= 2:\n            english, arabic = parts[0], parts[1]\n            english_sentences.append(english)\n            arabic_sentences.append(arabic)\n    return english_sentences, arabic_sentences\n\nfilepath = \"/kaggle/input/d/bedomostafa/en-to-ar/ara_.txt\" # find data p\nenglish_sentences, arabic_sentences = load_data(filepath)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:07:42.885853Z","iopub.execute_input":"2025-04-21T18:07:42.886066Z","iopub.status.idle":"2025-04-21T18:07:42.908933Z","shell.execute_reply.started":"2025-04-21T18:07:42.886050Z","shell.execute_reply":"2025-04-21T18:07:42.908241Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# **Visualize Data**","metadata":{}},{"cell_type":"code","source":"def visualize_pairs(english_sentences, arabic_sentences, num_samples=10):\n    data = []\n    for i in range(min(num_samples, len(english_sentences))):\n        data.append([i+1, english_sentences[i], arabic_sentences[i]])\n    \n    print(tabulate(data, headers=[\"#\", \"English\", \"Arabic\"], tablefmt=\"fancy_grid\"))\n\ndef visualize_lengths(english_sentences, arabic_sentences):\n    en_lengths = [len(sentence.split()) for sentence in english_sentences]\n    ar_lengths = [len(sentence.split()) for sentence in arabic_sentences]\n\n    plt.figure(figsize=(12, 6))\n\n    plt.hist(en_lengths, bins=30, alpha=0.6, label='English Sentence Lengths', color='blue')\n    plt.hist(ar_lengths, bins=30, alpha=0.6, label='Arabic Sentence Lengths', color='green')\n\n    plt.title('Sentence Length Distribution')\n    plt.xlabel('Number of Words')\n    plt.ylabel('Number of Sentences')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\n\nvisualize_pairs(english_sentences, arabic_sentences)\nvisualize_lengths(english_sentences, arabic_sentences)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:07:42.909644Z","iopub.execute_input":"2025-04-21T18:07:42.909923Z","iopub.status.idle":"2025-04-21T18:07:43.259218Z","shell.execute_reply.started":"2025-04-21T18:07:42.909907Z","shell.execute_reply":"2025-04-21T18:07:43.258563Z"}},"outputs":[{"name":"stdout","text":"╒═════╤═══════════╤══════════╕\n│   # │ English   │ Arabic   │\n╞═════╪═══════════╪══════════╡\n│   1 │ Hi.       │ مرحبًا.   │\n├─────┼───────────┼──────────┤\n│   2 │ Run!      │ اركض!    │\n├─────┼───────────┼──────────┤\n│   3 │ Help!     │ النجدة!  │\n├─────┼───────────┼──────────┤\n│   4 │ Jump!     │ اقفز!    │\n├─────┼───────────┼──────────┤\n│   5 │ Stop!     │ قف!      │\n├─────┼───────────┼──────────┤\n│   6 │ Go on.    │ داوم.    │\n├─────┼───────────┼──────────┤\n│   7 │ Go on.    │ استمر.   │\n├─────┼───────────┼──────────┤\n│   8 │ Hello!    │ مرحباً.   │\n├─────┼───────────┼──────────┤\n│   9 │ Hurry!    │ تعجّل!    │\n├─────┼───────────┼──────────┤\n│  10 │ Hurry!    │ استعجل!  │\n╘═════╧═══════════╧══════════╛\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"# **Data preprocessing**","metadata":{}},{"cell_type":"code","source":"def preprocess_data(sentences, lang):\n    if lang == 'ar':\n        # Arabic preprocessing\n        processed_sentences = []\n        for sentence in sentences:\n            # Normalize Arabic text, remove diacritics, etc.\n            sentence = re.sub(r'[^\\w\\s]', '', sentence)\n            processed_sentences.append(['<sos>'] + list(sentence) + ['<eos>'])\n    else:\n        # English preprocessing\n        processed_sentences = []\n        for sentence in sentences:\n            # Convert to lowercase, tokenize by character for simplicity\n            sentence = sentence.lower()\n            sentence = re.sub(r'[^\\w\\s]', '', sentence)\n            processed_sentences.append(['<sos>'] + list(sentence) + ['<eos>'])\n    \n    return processed_sentences\n\npreprocessed_en = preprocess_data(english_sentences, 'en')\npreprocessed_ar = preprocess_data(arabic_sentences, 'ar')\n\nfor i in range(10):\n    print(f\"English [{i+1}]:\", preprocessed_en[i])\n    print(f\"Arabic  [{i+1}]:\", preprocessed_ar[i])\n    print(\"-\" * 70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:07:43.259866Z","iopub.execute_input":"2025-04-21T18:07:43.260102Z","iopub.status.idle":"2025-04-21T18:07:43.419211Z","shell.execute_reply.started":"2025-04-21T18:07:43.260076Z","shell.execute_reply":"2025-04-21T18:07:43.418500Z"}},"outputs":[{"name":"stdout","text":"English [1]: ['<sos>', 'h', 'i', '<eos>']\nArabic  [1]: ['<sos>', 'م', 'ر', 'ح', 'ب', 'ا', '<eos>']\n----------------------------------------------------------------------\nEnglish [2]: ['<sos>', 'r', 'u', 'n', '<eos>']\nArabic  [2]: ['<sos>', 'ا', 'ر', 'ك', 'ض', '<eos>']\n----------------------------------------------------------------------\nEnglish [3]: ['<sos>', 'h', 'e', 'l', 'p', '<eos>']\nArabic  [3]: ['<sos>', 'ا', 'ل', 'ن', 'ج', 'د', 'ة', '<eos>']\n----------------------------------------------------------------------\nEnglish [4]: ['<sos>', 'j', 'u', 'm', 'p', '<eos>']\nArabic  [4]: ['<sos>', 'ا', 'ق', 'ف', 'ز', '<eos>']\n----------------------------------------------------------------------\nEnglish [5]: ['<sos>', 's', 't', 'o', 'p', '<eos>']\nArabic  [5]: ['<sos>', 'ق', 'ف', '<eos>']\n----------------------------------------------------------------------\nEnglish [6]: ['<sos>', 'g', 'o', ' ', 'o', 'n', '<eos>']\nArabic  [6]: ['<sos>', 'د', 'ا', 'و', 'م', '<eos>']\n----------------------------------------------------------------------\nEnglish [7]: ['<sos>', 'g', 'o', ' ', 'o', 'n', '<eos>']\nArabic  [7]: ['<sos>', 'ا', 'س', 'ت', 'م', 'ر', '<eos>']\n----------------------------------------------------------------------\nEnglish [8]: ['<sos>', 'h', 'e', 'l', 'l', 'o', '<eos>']\nArabic  [8]: ['<sos>', 'م', 'ر', 'ح', 'ب', 'ا', '<eos>']\n----------------------------------------------------------------------\nEnglish [9]: ['<sos>', 'h', 'u', 'r', 'r', 'y', '<eos>']\nArabic  [9]: ['<sos>', 'ت', 'ع', 'ج', 'ل', '<eos>']\n----------------------------------------------------------------------\nEnglish [10]: ['<sos>', 'h', 'u', 'r', 'r', 'y', '<eos>']\nArabic  [10]: ['<sos>', 'ا', 'س', 'ت', 'ع', 'ج', 'ل', '<eos>']\n----------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# **Build Vocabulary**","metadata":{}},{"cell_type":"code","source":"def build_vocab(sentences, max_size=None):\n    word_counts = {}\n    for sentence in sentences:\n        for word in sentence:\n            word_counts[word] = word_counts.get(word, 0) + 1\n\n    sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n\n    vocab = {'<pad>': 0, '<unk>': 1}\n    if max_size:\n        sorted_words = sorted_words[:max_size - 2]\n\n    for word, _ in sorted_words:\n        vocab[word] = len(vocab)\n\n    return vocab\n\nen_vocab = build_vocab(preprocessed_en)\nar_vocab = build_vocab(preprocessed_ar)\n\nprint(\"Sample English vocab:\", list(en_vocab.items())[:1000])\nprint(\"#\" * 136)\nprint(\"Sample Arabic vocab:\", list(ar_vocab.items())[:1000])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:07:43.419878Z","iopub.execute_input":"2025-04-21T18:07:43.420087Z","iopub.status.idle":"2025-04-21T18:07:43.476947Z","shell.execute_reply.started":"2025-04-21T18:07:43.420062Z","shell.execute_reply":"2025-04-21T18:07:43.476407Z"}},"outputs":[{"name":"stdout","text":"Sample English vocab: [('<pad>', 0), ('<unk>', 1), (' ', 2), ('e', 3), ('t', 4), ('o', 5), ('a', 6), ('i', 7), ('s', 8), ('n', 9), ('h', 10), ('r', 11), ('<sos>', 12), ('<eos>', 13), ('l', 14), ('d', 15), ('y', 16), ('u', 17), ('m', 18), ('w', 19), ('c', 20), ('g', 21), ('p', 22), ('f', 23), ('k', 24), ('b', 25), ('v', 26), ('j', 27), ('x', 28), ('q', 29), ('z', 30), ('0', 31), ('1', 32), ('9', 33), ('2', 34), ('3', 35), ('5', 36), ('6', 37), ('7', 38), ('8', 39), ('4', 40)]\n########################################################################################################################################\nSample Arabic vocab: [('<pad>', 0), ('<unk>', 1), (' ', 2), ('ا', 3), ('ل', 4), ('ي', 5), ('ن', 6), ('م', 7), ('<sos>', 8), ('<eos>', 9), ('ت', 10), ('أ', 11), ('ر', 12), ('ك', 13), ('ب', 14), ('ع', 15), ('ه', 16), ('و', 17), ('د', 18), ('س', 19), ('ف', 20), ('ة', 21), ('ق', 22), ('ح', 23), ('ج', 24), ('ذ', 25), ('ط', 26), ('إ', 27), ('ى', 28), ('ش', 29), ('ص', 30), ('خ', 31), ('ض', 32), ('ث', 33), ('ز', 34), ('غ', 35), ('ئ', 36), ('ء', 37), ('ظ', 38), ('آ', 39), ('ؤ', 40), ('1', 41), ('0', 42), ('ی', 43), ('9', 44), ('١', 45), ('e', 46), ('3', 47), ('٩', 48), ('2', 49), ('t', 50), ('n', 51), ('a', 52), ('o', 53), ('7', 54), ('٦', 55), ('٥', 56), ('5', 57), ('i', 58), ('r', 59), ('٣', 60), ('l', 61), ('8', 62), ('f', 63), ('٨', 64), ('٤', 65), ('٠', 66), ('s', 67), ('4', 68), ('6', 69), ('g', 70), ('y', 71), ('d', 72), ('h', 73), ('۹', 74), ('۰', 75), ('٢', 76), ('٧', 77), ('F', 78), ('x', 79), ('M', 80), ('P', 81), ('I', 82), ('ٱ', 83), ('۱', 84), ('T', 85), ('b', 86), ('c', 87), ('u', 88), ('m', 89)]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# **Convert sentences to indices**","metadata":{}},{"cell_type":"code","source":"def sentences_to_indices(sentences, vocab):\n    indices = []\n    for sentence in sentences:\n        indices.append([vocab.get(word, vocab['<unk>']) for word in sentence])\n    return indices\n\n# Convert preprocessed sentences to indices\nen_indices = sentences_to_indices(preprocessed_en, en_vocab)\nar_indices = sentences_to_indices(preprocessed_ar, ar_vocab)\n\nfor i in range(10):\n    print(f\"English [{i+1}]: {preprocessed_en[i]}\")\n    print(f\"Indices  [{i+1}]: {en_indices[i]}\")\n    print(f\"Arabic  [{i+1}]: {preprocessed_ar[i]}\")\n    print(f\"Indices  [{i+1}]: {ar_indices[i]}\")\n    print(\"-\" * 80)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:07:43.477578Z","iopub.execute_input":"2025-04-21T18:07:43.478008Z","iopub.status.idle":"2025-04-21T18:07:43.538591Z","shell.execute_reply.started":"2025-04-21T18:07:43.477984Z","shell.execute_reply":"2025-04-21T18:07:43.537881Z"}},"outputs":[{"name":"stdout","text":"English [1]: ['<sos>', 'h', 'i', '<eos>']\nIndices  [1]: [12, 10, 7, 13]\nArabic  [1]: ['<sos>', 'م', 'ر', 'ح', 'ب', 'ا', '<eos>']\nIndices  [1]: [8, 7, 12, 23, 14, 3, 9]\n--------------------------------------------------------------------------------\nEnglish [2]: ['<sos>', 'r', 'u', 'n', '<eos>']\nIndices  [2]: [12, 11, 17, 9, 13]\nArabic  [2]: ['<sos>', 'ا', 'ر', 'ك', 'ض', '<eos>']\nIndices  [2]: [8, 3, 12, 13, 32, 9]\n--------------------------------------------------------------------------------\nEnglish [3]: ['<sos>', 'h', 'e', 'l', 'p', '<eos>']\nIndices  [3]: [12, 10, 3, 14, 22, 13]\nArabic  [3]: ['<sos>', 'ا', 'ل', 'ن', 'ج', 'د', 'ة', '<eos>']\nIndices  [3]: [8, 3, 4, 6, 24, 18, 21, 9]\n--------------------------------------------------------------------------------\nEnglish [4]: ['<sos>', 'j', 'u', 'm', 'p', '<eos>']\nIndices  [4]: [12, 27, 17, 18, 22, 13]\nArabic  [4]: ['<sos>', 'ا', 'ق', 'ف', 'ز', '<eos>']\nIndices  [4]: [8, 3, 22, 20, 34, 9]\n--------------------------------------------------------------------------------\nEnglish [5]: ['<sos>', 's', 't', 'o', 'p', '<eos>']\nIndices  [5]: [12, 8, 4, 5, 22, 13]\nArabic  [5]: ['<sos>', 'ق', 'ف', '<eos>']\nIndices  [5]: [8, 22, 20, 9]\n--------------------------------------------------------------------------------\nEnglish [6]: ['<sos>', 'g', 'o', ' ', 'o', 'n', '<eos>']\nIndices  [6]: [12, 21, 5, 2, 5, 9, 13]\nArabic  [6]: ['<sos>', 'د', 'ا', 'و', 'م', '<eos>']\nIndices  [6]: [8, 18, 3, 17, 7, 9]\n--------------------------------------------------------------------------------\nEnglish [7]: ['<sos>', 'g', 'o', ' ', 'o', 'n', '<eos>']\nIndices  [7]: [12, 21, 5, 2, 5, 9, 13]\nArabic  [7]: ['<sos>', 'ا', 'س', 'ت', 'م', 'ر', '<eos>']\nIndices  [7]: [8, 3, 19, 10, 7, 12, 9]\n--------------------------------------------------------------------------------\nEnglish [8]: ['<sos>', 'h', 'e', 'l', 'l', 'o', '<eos>']\nIndices  [8]: [12, 10, 3, 14, 14, 5, 13]\nArabic  [8]: ['<sos>', 'م', 'ر', 'ح', 'ب', 'ا', '<eos>']\nIndices  [8]: [8, 7, 12, 23, 14, 3, 9]\n--------------------------------------------------------------------------------\nEnglish [9]: ['<sos>', 'h', 'u', 'r', 'r', 'y', '<eos>']\nIndices  [9]: [12, 10, 17, 11, 11, 16, 13]\nArabic  [9]: ['<sos>', 'ت', 'ع', 'ج', 'ل', '<eos>']\nIndices  [9]: [8, 10, 15, 24, 4, 9]\n--------------------------------------------------------------------------------\nEnglish [10]: ['<sos>', 'h', 'u', 'r', 'r', 'y', '<eos>']\nIndices  [10]: [12, 10, 17, 11, 11, 16, 13]\nArabic  [10]: ['<sos>', 'ا', 'س', 'ت', 'ع', 'ج', 'ل', '<eos>']\nIndices  [10]: [8, 3, 19, 10, 15, 24, 4, 9]\n--------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# **Use custom data into a PyTorch DataLoader**","metadata":{}},{"cell_type":"code","source":"class TranslationDataset(Dataset):\n    def __init__(self, src_data, tgt_data): # Stores source & target indexed sentences\n        self.src_data = src_data # list of padded token indices (English)\n        self.tgt_data = tgt_data # list of padded token indices (Arabic)\n    \n    def __len__(self): # Returns total number of sentence pairs\n        return len(self.src_data)\n    \n    def __getitem__(self, idx): # Returns one source-target pair as tensors\n        return torch.tensor(self.src_data[idx]), torch.tensor(self.tgt_data[idx])\n\n# data loader\ndef collate_DataLoader(batch):\n    src_batch, tgt_batch = zip(*batch)\n    src_batch = pad_sequence(src_batch, batch_first=True, padding_value=0)\n    tgt_batch = pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n    return src_batch, tgt_batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:07:43.539323Z","iopub.execute_input":"2025-04-21T18:07:43.539820Z","iopub.status.idle":"2025-04-21T18:07:43.544172Z","shell.execute_reply.started":"2025-04-21T18:07:43.539797Z","shell.execute_reply":"2025-04-21T18:07:43.543631Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# **Transformer model components**","metadata":{}},{"cell_type":"code","source":"class AttentionHead(nn.Module):\n    def __init__(self, model_dim, num_heads):\n        super(AttentionHead, self).__init__()\n        assert model_dim % num_heads == 0, \"model_dim must be divisible by num_heads\"\n\n        self.model_dim = model_dim\n        self.num_heads = num_heads\n        self.head_dim = model_dim // num_heads\n\n        self.query_layer = nn.Linear(model_dim, model_dim)\n        self.key_layer = nn.Linear(model_dim, model_dim)\n        self.value_layer = nn.Linear(model_dim, model_dim)\n        self.output_layer = nn.Linear(model_dim, model_dim)\n\n    def compute_attention(self, query, key, value, mask=None):\n        # Compute attention scores (dot product of query and key)\n        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.head_dim)\n\n        # Check if mask is provided\n        if mask is not None:\n            # Expand mask to match the dimensions of attention scores (batch_size, num_heads, seq_len, seq_len)\n            mask = mask.unsqueeze(1).repeat(1, query.size(1), 1, 1)\n\n            # Apply the mask to the scores (masked_fill expects the mask to have the same shape as scores)\n            scores = scores.masked_fill(mask == 0, -1e9)\n\n        # Compute the attention probabilities\n        attention_probs = torch.softmax(scores, dim=-1)\n\n        # Multiply the attention probabilities with the value tensor\n        output = torch.matmul(attention_probs, value)\n\n        return output\n\n    def split_heads(self, tensor):\n        batch_size, seq_len, model_dim = tensor.size()\n        return tensor.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n\n    def merge_heads(self, tensor):\n        batch_size, num_heads, seq_len, head_dim = tensor.size()\n        return tensor.transpose(1, 2).contiguous().view(batch_size, seq_len, self.model_dim)\n\n    def forward(self, query, key, value, mask=None):\n        query = self.split_heads(self.query_layer(query))\n        key = self.split_heads(self.key_layer(key))\n        value = self.split_heads(self.value_layer(value))\n\n        attention_output = self.compute_attention(query, key, value, mask)\n        output = self.output_layer(self.merge_heads(attention_output))\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:07:43.546561Z","iopub.execute_input":"2025-04-21T18:07:43.546757Z","iopub.status.idle":"2025-04-21T18:07:43.558088Z","shell.execute_reply.started":"2025-04-21T18:07:43.546742Z","shell.execute_reply":"2025-04-21T18:07:43.557582Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class FeedForwardNetwork(nn.Module):\n    def __init__(self, model_dim, hidden_dim):\n        super(FeedForwardNetwork, self).__init__()\n        self.fc1 = nn.Linear(model_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, model_dim)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        return self.fc2(self.relu(self.fc1(x)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:07:43.558875Z","iopub.execute_input":"2025-04-21T18:07:43.559106Z","iopub.status.idle":"2025-04-21T18:07:43.574028Z","shell.execute_reply.started":"2025-04-21T18:07:43.559083Z","shell.execute_reply":"2025-04-21T18:07:43.573397Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class PositionalEmbedding(nn.Module):\n    def __init__(self, model_dim, max_len):\n        super(PositionalEmbedding, self).__init__()\n\n        pos_enc = torch.zeros(max_len, model_dim)\n        positions = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, model_dim, 2).float() * -(math.log(10000.0) / model_dim))\n\n        pos_enc[:, 0::2] = torch.sin(positions * div_term)\n        pos_enc[:, 1::2] = torch.cos(positions * div_term)\n\n        self.register_buffer('pos_enc', pos_enc.unsqueeze(0))\n\n    def forward(self, x):\n        return x + self.pos_enc[:, :x.size(1)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:07:43.574691Z","iopub.execute_input":"2025-04-21T18:07:43.574840Z","iopub.status.idle":"2025-04-21T18:07:43.587269Z","shell.execute_reply.started":"2025-04-21T18:07:43.574828Z","shell.execute_reply":"2025-04-21T18:07:43.586615Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class EncoderBlock(nn.Module):\n    def __init__(self, model_dim, num_heads, hidden_dim, dropout_rate):\n        super(EncoderBlock, self).__init__()\n        self.self_attention = AttentionHead(model_dim, num_heads)\n        self.feed_forward = FeedForwardNetwork(model_dim, hidden_dim)\n        self.norm1 = nn.LayerNorm(model_dim)\n        self.norm2 = nn.LayerNorm(model_dim)\n        self.dropout = nn.Dropout(dropout_rate)\n\n    def forward(self, encoder_input, src_mask):\n        attention_out = self.self_attention(encoder_input, encoder_input, encoder_input, src_mask)\n        encoder_input = self.norm1(encoder_input + self.dropout(attention_out))\n        ff_out = self.feed_forward(encoder_input)\n        encoder_input = self.norm2(encoder_input + self.dropout(ff_out))\n        return encoder_input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:07:43.587964Z","iopub.execute_input":"2025-04-21T18:07:43.588181Z","iopub.status.idle":"2025-04-21T18:07:43.603393Z","shell.execute_reply.started":"2025-04-21T18:07:43.588162Z","shell.execute_reply":"2025-04-21T18:07:43.602878Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"class DecoderBlock(nn.Module):\n    def __init__(self, model_dim, num_heads, hidden_dim, dropout_rate):\n        super(DecoderBlock, self).__init__()\n        self.self_attention = AttentionHead(model_dim, num_heads)\n        self.cross_attention = AttentionHead(model_dim, num_heads)\n        self.feed_forward = FeedForwardNetwork(model_dim, hidden_dim)\n        self.norm1 = nn.LayerNorm(model_dim)\n        self.norm2 = nn.LayerNorm(model_dim)\n        self.norm3 = nn.LayerNorm(model_dim)\n        self.dropout = nn.Dropout(dropout_rate)\n\n    def forward(self, decoder_input, encoder_output, src_mask, tgt_mask):\n        attention_out = self.self_attention(decoder_input, decoder_input, decoder_input, tgt_mask)\n        decoder_input = self.norm1(decoder_input + self.dropout(attention_out))\n        cross_attention_out = self.cross_attention(decoder_input, encoder_output, encoder_output, src_mask)\n        decoder_input = self.norm2(decoder_input + self.dropout(cross_attention_out))\n        ff_out = self.feed_forward(decoder_input)\n        decoder_input = self.norm3(decoder_input + self.dropout(ff_out))\n        return decoder_input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:07:43.604010Z","iopub.execute_input":"2025-04-21T18:07:43.604183Z","iopub.status.idle":"2025-04-21T18:07:43.617029Z","shell.execute_reply.started":"2025-04-21T18:07:43.604170Z","shell.execute_reply":"2025-04-21T18:07:43.616398Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"class TransformerModel(nn.Module):\n    def __init__(self, input_vocab_size, output_vocab_size, model_dim, num_heads, num_layers, hidden_dim, max_len, dropout_rate):\n        super(TransformerModel, self).__init__()\n        self.encoder_embedding = nn.Embedding(input_vocab_size, model_dim)\n        self.decoder_embedding = nn.Embedding(output_vocab_size, model_dim)\n        self.positional_embedding = PositionalEmbedding(model_dim, max_len)\n\n        self.encoder_blocks = nn.ModuleList([EncoderBlock(model_dim, num_heads, hidden_dim, dropout_rate) for _ in range(num_layers)])\n        self.decoder_blocks = nn.ModuleList([DecoderBlock(model_dim, num_heads, hidden_dim, dropout_rate) for _ in range(num_layers)])\n\n        self.fc_out = nn.Linear(model_dim, output_vocab_size)\n        self.dropout = nn.Dropout(dropout_rate)\n\n    def generate_mask(self, source, target):\n        # Ensure masks are created on the same device as the inputs\n        src_mask = (source != 0).unsqueeze(1).to(source.device)\n        tgt_mask = (target != 0).unsqueeze(1).to(target.device)\n\n        seq_len = target.size(1)\n        no_peak_mask = (1 - torch.triu(torch.ones(1, seq_len, seq_len), diagonal=1)).bool().to(target.device)\n        tgt_mask = tgt_mask & no_peak_mask\n\n        return src_mask, tgt_mask\n\n    def forward(self, src_input, tgt_input):\n        src_mask, tgt_mask = self.generate_mask(src_input, tgt_input)\n        src_embedded = self.dropout(self.positional_embedding(self.encoder_embedding(src_input)))\n        tgt_embedded = self.dropout(self.positional_embedding(self.decoder_embedding(tgt_input)))\n\n        encoder_output = src_embedded\n        for encoder_block in self.encoder_blocks:\n            encoder_output = encoder_block(encoder_output, src_mask)\n\n        decoder_output = tgt_embedded\n        for decoder_block in self.decoder_blocks:\n            decoder_output = decoder_block(decoder_output, encoder_output, src_mask, tgt_mask)\n\n        output = self.fc_out(decoder_output)\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:07:43.617578Z","iopub.execute_input":"2025-04-21T18:07:43.617749Z","iopub.status.idle":"2025-04-21T18:07:43.629661Z","shell.execute_reply.started":"2025-04-21T18:07:43.617736Z","shell.execute_reply":"2025-04-21T18:07:43.629079Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# **Function to load and prepare data**","metadata":{}},{"cell_type":"code","source":"def prepare_data(batch_size=64):\n    print(\"Loading and preprocessing data...\")\n\n    try:\n        english_sentences, arabic_sentences = load_data(\"/kaggle/input/d/bedomostafa/en-to-ar/ara_.txt\")\n        print(f\"Loaded {len(english_sentences)} sentence pairs\")\n        \n        # EN → AR direction\n        english_processed = preprocess_data(english_sentences, 'en')\n        arabic_processed = preprocess_data(arabic_sentences, 'ar')\n        \n        english_vocab = build_vocab(english_processed, max_size=5000)\n        arabic_vocab = build_vocab(arabic_processed, max_size=5000)\n\n        english_indices = sentences_to_indices(english_processed, english_vocab)\n        arabic_indices = sentences_to_indices(arabic_processed, arabic_vocab)\n\n        dataset = TranslationDataset(english_indices, arabic_indices)\n        dataloader = DataLoader(\n            dataset,\n            batch_size=batch_size,\n            shuffle=True,\n            collate_fn=collate_DataLoader\n        )\n\n        return dataloader, len(english_vocab), len(arabic_vocab), english_vocab, arabic_vocab\n\n    except Exception as e:\n        print(f\"Error loading data: {e}\")\n        return None, 5000, 5000, None, None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:07:43.630326Z","iopub.execute_input":"2025-04-21T18:07:43.630574Z","iopub.status.idle":"2025-04-21T18:07:43.646085Z","shell.execute_reply.started":"2025-04-21T18:07:43.630554Z","shell.execute_reply":"2025-04-21T18:07:43.645563Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# **Evaluation function**","metadata":{}},{"cell_type":"code","source":"def evaluate(model, dataloader, loss_fn, num_batches=5):\n    model.eval()\n    total_loss = 0\n    with torch.no_grad():\n        for i, (src, tgt) in enumerate(dataloader):\n            if i >= num_batches:\n                break\n            \n            src, tgt = src.to(device), tgt.to(device)\n            \n            # Forward pass\n            predictions = model(src, tgt[:, :-1])\n            \n            # Compute loss\n            loss = loss_fn(predictions.contiguous().view(-1, predictions.size(-1)), \n                          tgt[:, 1:].contiguous().view(-1))\n            \n            total_loss += loss.item()\n    \n    return total_loss / min(num_batches, len(dataloader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:07:43.646756Z","iopub.execute_input":"2025-04-21T18:07:43.646937Z","iopub.status.idle":"2025-04-21T18:07:43.662551Z","shell.execute_reply.started":"2025-04-21T18:07:43.646923Z","shell.execute_reply":"2025-04-21T18:07:43.661981Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# **Set hyperparameters**","metadata":{}},{"cell_type":"code","source":"model_dim = 256  # Reduced from 512 to fit in memory\nnum_heads = 8\nnum_layers = 4   # Reduced from 6 to fit in memory\nhidden_dim = 1024 # Reduced from 2048 to fit in memory\nmax_len = 300     # Increased for real sentences\ndropout_rate = 0.1\nbatch_size = 32   # Reduced batch size\nnum_epochs = 300","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:07:43.663176Z","iopub.execute_input":"2025-04-21T18:07:43.663395Z","iopub.status.idle":"2025-04-21T18:07:43.675899Z","shell.execute_reply.started":"2025-04-21T18:07:43.663354Z","shell.execute_reply":"2025-04-21T18:07:43.675268Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Prepare data\ndataloader, input_vocab_size, output_vocab_size, src_vocab, tgt_vocab = prepare_data(batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:07:43.676636Z","iopub.execute_input":"2025-04-21T18:07:43.676824Z","iopub.status.idle":"2025-04-21T18:07:43.882083Z","shell.execute_reply.started":"2025-04-21T18:07:43.676811Z","shell.execute_reply":"2025-04-21T18:07:43.881574Z"}},"outputs":[{"name":"stdout","text":"Loading and preprocessing data...\nLoaded 10742 sentence pairs\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"# **Initialize the model with data**","metadata":{}},{"cell_type":"code","source":"transformer_model = TransformerModel(\n    input_vocab_size, output_vocab_size, model_dim, num_heads, \n    num_layers, hidden_dim, max_len, dropout_rate\n).to(device)\n\n# Set loss function and optimizer\nloss_fn = nn.CrossEntropyLoss(ignore_index=0).to(device)\noptimizer = optim.Adam(transformer_model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n\n# Training loop\nprint(\"Starting training...\")\ntransformer_model.train()\nfor epoch in range(num_epochs):\n    total_loss = 0\n    num_batches = 0\n    \n    for src_batch, tgt_batch in dataloader:\n        src_batch = src_batch.to(device)\n        tgt_batch = tgt_batch.to(device)\n        \n        optimizer.zero_grad()\n\n        # Forward pass\n        predictions = transformer_model(src_batch, tgt_batch[:, :-1])\n\n        # Compute loss\n        loss = loss_fn(predictions.contiguous().view(-1, output_vocab_size), \n                      tgt_batch[:, 1:].contiguous().view(-1))\n\n        # Backpropagation\n        loss.backward()\n        \n        # Gradient clipping to prevent exploding gradients\n        torch.nn.utils.clip_grad_norm_(transformer_model.parameters(), max_norm=1.0)\n        \n        optimizer.step()\n        \n        total_loss += loss.item()\n        num_batches += 1\n    \n    avg_loss = total_loss / num_batches\n    scheduler.step(avg_loss)\n    \n    # Evaluate on a few batches\n    val_loss = evaluate(transformer_model, dataloader, loss_fn)\n    \n    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {avg_loss:.6f}, Validation Loss: {val_loss:.6f}\")\n    \n    # Save model checkpoint\n    if (epoch + 1) % 10 == 0:\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': transformer_model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': avg_loss,\n        }, f'transformer_checkpoint_epoch_{epoch+1}.pt')    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:07:43.882807Z","iopub.execute_input":"2025-04-21T18:07:43.883045Z","iopub.status.idle":"2025-04-21T19:19:37.076283Z","shell.execute_reply.started":"2025-04-21T18:07:43.883025Z","shell.execute_reply":"2025-04-21T19:19:37.075541Z"}},"outputs":[{"name":"stdout","text":"Starting training...\nEpoch 1/300, Training Loss: 2.662452, Validation Loss: 2.345596\nEpoch 2/300, Training Loss: 2.237627, Validation Loss: 2.106006\nEpoch 3/300, Training Loss: 2.023877, Validation Loss: 1.969534\nEpoch 4/300, Training Loss: 1.878667, Validation Loss: 1.780982\nEpoch 5/300, Training Loss: 1.763327, Validation Loss: 1.685230\nEpoch 6/300, Training Loss: 1.666820, Validation Loss: 1.567161\nEpoch 7/300, Training Loss: 1.576569, Validation Loss: 1.555448\nEpoch 8/300, Training Loss: 1.495467, Validation Loss: 1.437356\nEpoch 9/300, Training Loss: 1.416110, Validation Loss: 1.277259\nEpoch 10/300, Training Loss: 1.341807, Validation Loss: 1.288356\nEpoch 11/300, Training Loss: 1.266654, Validation Loss: 1.143169\nEpoch 12/300, Training Loss: 1.194518, Validation Loss: 1.100299\nEpoch 13/300, Training Loss: 1.121665, Validation Loss: 0.988710\nEpoch 14/300, Training Loss: 1.050868, Validation Loss: 0.954571\nEpoch 15/300, Training Loss: 0.977717, Validation Loss: 0.871454\nEpoch 16/300, Training Loss: 0.902745, Validation Loss: 0.737256\nEpoch 17/300, Training Loss: 0.832471, Validation Loss: 0.710959\nEpoch 18/300, Training Loss: 0.759583, Validation Loss: 0.651448\nEpoch 19/300, Training Loss: 0.688367, Validation Loss: 0.558591\nEpoch 20/300, Training Loss: 0.620367, Validation Loss: 0.466292\nEpoch 21/300, Training Loss: 0.555491, Validation Loss: 0.468780\nEpoch 22/300, Training Loss: 0.493415, Validation Loss: 0.377977\nEpoch 23/300, Training Loss: 0.436342, Validation Loss: 0.372915\nEpoch 24/300, Training Loss: 0.382095, Validation Loss: 0.301356\nEpoch 25/300, Training Loss: 0.334880, Validation Loss: 0.240660\nEpoch 26/300, Training Loss: 0.294109, Validation Loss: 0.221137\nEpoch 27/300, Training Loss: 0.259465, Validation Loss: 0.213275\nEpoch 28/300, Training Loss: 0.230428, Validation Loss: 0.185500\nEpoch 29/300, Training Loss: 0.209132, Validation Loss: 0.145449\nEpoch 30/300, Training Loss: 0.187869, Validation Loss: 0.146722\nEpoch 31/300, Training Loss: 0.172195, Validation Loss: 0.115870\nEpoch 32/300, Training Loss: 0.160337, Validation Loss: 0.127799\nEpoch 33/300, Training Loss: 0.151685, Validation Loss: 0.113162\nEpoch 34/300, Training Loss: 0.141780, Validation Loss: 0.123938\nEpoch 35/300, Training Loss: 0.133930, Validation Loss: 0.111259\nEpoch 36/300, Training Loss: 0.128130, Validation Loss: 0.071692\nEpoch 37/300, Training Loss: 0.123344, Validation Loss: 0.102017\nEpoch 38/300, Training Loss: 0.117968, Validation Loss: 0.089425\nEpoch 39/300, Training Loss: 0.114662, Validation Loss: 0.075148\nEpoch 40/300, Training Loss: 0.109365, Validation Loss: 0.074825\nEpoch 41/300, Training Loss: 0.107304, Validation Loss: 0.082302\nEpoch 42/300, Training Loss: 0.104609, Validation Loss: 0.074115\nEpoch 43/300, Training Loss: 0.102048, Validation Loss: 0.081537\nEpoch 44/300, Training Loss: 0.099629, Validation Loss: 0.070339\nEpoch 45/300, Training Loss: 0.097137, Validation Loss: 0.094601\nEpoch 46/300, Training Loss: 0.094401, Validation Loss: 0.082399\nEpoch 47/300, Training Loss: 0.092672, Validation Loss: 0.070649\nEpoch 48/300, Training Loss: 0.089707, Validation Loss: 0.076233\nEpoch 49/300, Training Loss: 0.088728, Validation Loss: 0.068449\nEpoch 50/300, Training Loss: 0.086583, Validation Loss: 0.065665\nEpoch 51/300, Training Loss: 0.084022, Validation Loss: 0.066389\nEpoch 52/300, Training Loss: 0.082731, Validation Loss: 0.065031\nEpoch 53/300, Training Loss: 0.082942, Validation Loss: 0.061812\nEpoch 54/300, Training Loss: 0.080472, Validation Loss: 0.053150\nEpoch 55/300, Training Loss: 0.079190, Validation Loss: 0.048187\nEpoch 56/300, Training Loss: 0.076691, Validation Loss: 0.055919\nEpoch 57/300, Training Loss: 0.076360, Validation Loss: 0.052194\nEpoch 58/300, Training Loss: 0.074711, Validation Loss: 0.069960\nEpoch 59/300, Training Loss: 0.074191, Validation Loss: 0.048707\nEpoch 60/300, Training Loss: 0.072347, Validation Loss: 0.060483\nEpoch 61/300, Training Loss: 0.070960, Validation Loss: 0.048998\nEpoch 62/300, Training Loss: 0.070688, Validation Loss: 0.051480\nEpoch 63/300, Training Loss: 0.068419, Validation Loss: 0.044156\nEpoch 64/300, Training Loss: 0.068387, Validation Loss: 0.094975\nEpoch 65/300, Training Loss: 0.067930, Validation Loss: 0.054287\nEpoch 66/300, Training Loss: 0.066510, Validation Loss: 0.048457\nEpoch 67/300, Training Loss: 0.064807, Validation Loss: 0.044787\nEpoch 68/300, Training Loss: 0.064258, Validation Loss: 0.045769\nEpoch 69/300, Training Loss: 0.062834, Validation Loss: 0.051962\nEpoch 70/300, Training Loss: 0.062591, Validation Loss: 0.038450\nEpoch 71/300, Training Loss: 0.060816, Validation Loss: 0.051912\nEpoch 72/300, Training Loss: 0.062616, Validation Loss: 0.045700\nEpoch 73/300, Training Loss: 0.060294, Validation Loss: 0.052884\nEpoch 74/300, Training Loss: 0.059595, Validation Loss: 0.044030\nEpoch 75/300, Training Loss: 0.058611, Validation Loss: 0.051525\nEpoch 76/300, Training Loss: 0.058485, Validation Loss: 0.034974\nEpoch 77/300, Training Loss: 0.058345, Validation Loss: 0.039903\nEpoch 78/300, Training Loss: 0.057622, Validation Loss: 0.035510\nEpoch 79/300, Training Loss: 0.056089, Validation Loss: 0.042974\nEpoch 80/300, Training Loss: 0.055707, Validation Loss: 0.050051\nEpoch 81/300, Training Loss: 0.054500, Validation Loss: 0.056228\nEpoch 82/300, Training Loss: 0.055019, Validation Loss: 0.036274\nEpoch 83/300, Training Loss: 0.054253, Validation Loss: 0.040893\nEpoch 84/300, Training Loss: 0.052484, Validation Loss: 0.042032\nEpoch 85/300, Training Loss: 0.052915, Validation Loss: 0.040440\nEpoch 86/300, Training Loss: 0.052365, Validation Loss: 0.048232\nEpoch 87/300, Training Loss: 0.052021, Validation Loss: 0.041387\nEpoch 88/300, Training Loss: 0.051234, Validation Loss: 0.031133\nEpoch 89/300, Training Loss: 0.051057, Validation Loss: 0.043935\nEpoch 90/300, Training Loss: 0.050010, Validation Loss: 0.043621\nEpoch 91/300, Training Loss: 0.049478, Validation Loss: 0.040098\nEpoch 92/300, Training Loss: 0.049601, Validation Loss: 0.031289\nEpoch 93/300, Training Loss: 0.048199, Validation Loss: 0.029326\nEpoch 94/300, Training Loss: 0.048165, Validation Loss: 0.034723\nEpoch 95/300, Training Loss: 0.048258, Validation Loss: 0.047120\nEpoch 96/300, Training Loss: 0.047139, Validation Loss: 0.033787\nEpoch 97/300, Training Loss: 0.047364, Validation Loss: 0.026792\nEpoch 98/300, Training Loss: 0.046323, Validation Loss: 0.031416\nEpoch 99/300, Training Loss: 0.045449, Validation Loss: 0.027468\nEpoch 100/300, Training Loss: 0.045676, Validation Loss: 0.031103\nEpoch 101/300, Training Loss: 0.045111, Validation Loss: 0.031846\nEpoch 102/300, Training Loss: 0.045121, Validation Loss: 0.037035\nEpoch 103/300, Training Loss: 0.043913, Validation Loss: 0.024977\nEpoch 104/300, Training Loss: 0.044048, Validation Loss: 0.033316\nEpoch 105/300, Training Loss: 0.043202, Validation Loss: 0.033570\nEpoch 106/300, Training Loss: 0.043994, Validation Loss: 0.029237\nEpoch 107/300, Training Loss: 0.042575, Validation Loss: 0.029858\nEpoch 108/300, Training Loss: 0.042919, Validation Loss: 0.031079\nEpoch 109/300, Training Loss: 0.042636, Validation Loss: 0.027905\nEpoch 110/300, Training Loss: 0.041580, Validation Loss: 0.036074\nEpoch 111/300, Training Loss: 0.041669, Validation Loss: 0.021827\nEpoch 112/300, Training Loss: 0.041026, Validation Loss: 0.043248\nEpoch 113/300, Training Loss: 0.040754, Validation Loss: 0.037519\nEpoch 114/300, Training Loss: 0.040962, Validation Loss: 0.022642\nEpoch 115/300, Training Loss: 0.039464, Validation Loss: 0.030588\nEpoch 116/300, Training Loss: 0.040638, Validation Loss: 0.029149\nEpoch 117/300, Training Loss: 0.040328, Validation Loss: 0.029762\nEpoch 118/300, Training Loss: 0.039793, Validation Loss: 0.025436\nEpoch 119/300, Training Loss: 0.039209, Validation Loss: 0.029524\nEpoch 120/300, Training Loss: 0.038828, Validation Loss: 0.033665\nEpoch 121/300, Training Loss: 0.039208, Validation Loss: 0.034510\nEpoch 122/300, Training Loss: 0.038456, Validation Loss: 0.027365\nEpoch 123/300, Training Loss: 0.038206, Validation Loss: 0.033701\nEpoch 124/300, Training Loss: 0.038165, Validation Loss: 0.035233\nEpoch 125/300, Training Loss: 0.037030, Validation Loss: 0.033568\nEpoch 126/300, Training Loss: 0.037671, Validation Loss: 0.020645\nEpoch 127/300, Training Loss: 0.037319, Validation Loss: 0.024924\nEpoch 128/300, Training Loss: 0.036385, Validation Loss: 0.031913\nEpoch 129/300, Training Loss: 0.035906, Validation Loss: 0.032305\nEpoch 130/300, Training Loss: 0.036446, Validation Loss: 0.025224\nEpoch 131/300, Training Loss: 0.035661, Validation Loss: 0.027603\nEpoch 132/300, Training Loss: 0.035760, Validation Loss: 0.030770\nEpoch 133/300, Training Loss: 0.034867, Validation Loss: 0.022095\nEpoch 134/300, Training Loss: 0.035205, Validation Loss: 0.023326\nEpoch 135/300, Training Loss: 0.034974, Validation Loss: 0.020023\nEpoch 136/300, Training Loss: 0.034542, Validation Loss: 0.028304\nEpoch 137/300, Training Loss: 0.034852, Validation Loss: 0.025322\nEpoch 138/300, Training Loss: 0.033926, Validation Loss: 0.027108\nEpoch 139/300, Training Loss: 0.034087, Validation Loss: 0.023932\nEpoch 140/300, Training Loss: 0.033613, Validation Loss: 0.023588\nEpoch 141/300, Training Loss: 0.033830, Validation Loss: 0.029740\nEpoch 142/300, Training Loss: 0.033853, Validation Loss: 0.027550\nEpoch 143/300, Training Loss: 0.033128, Validation Loss: 0.022787\nEpoch 144/300, Training Loss: 0.033356, Validation Loss: 0.031765\nEpoch 145/300, Training Loss: 0.032374, Validation Loss: 0.028449\nEpoch 146/300, Training Loss: 0.032651, Validation Loss: 0.026792\nEpoch 147/300, Training Loss: 0.033024, Validation Loss: 0.023355\nEpoch 148/300, Training Loss: 0.033308, Validation Loss: 0.036390\nEpoch 149/300, Training Loss: 0.032877, Validation Loss: 0.023171\nEpoch 150/300, Training Loss: 0.032638, Validation Loss: 0.031932\nEpoch 151/300, Training Loss: 0.032545, Validation Loss: 0.025129\nEpoch 152/300, Training Loss: 0.021788, Validation Loss: 0.011271\nEpoch 153/300, Training Loss: 0.019860, Validation Loss: 0.012817\nEpoch 154/300, Training Loss: 0.019971, Validation Loss: 0.009997\nEpoch 155/300, Training Loss: 0.019198, Validation Loss: 0.010154\nEpoch 156/300, Training Loss: 0.019359, Validation Loss: 0.013679\nEpoch 157/300, Training Loss: 0.018635, Validation Loss: 0.013555\nEpoch 158/300, Training Loss: 0.018105, Validation Loss: 0.014431\nEpoch 159/300, Training Loss: 0.018675, Validation Loss: 0.019217\nEpoch 160/300, Training Loss: 0.017767, Validation Loss: 0.013173\nEpoch 161/300, Training Loss: 0.018071, Validation Loss: 0.014570\nEpoch 162/300, Training Loss: 0.017677, Validation Loss: 0.013051\nEpoch 163/300, Training Loss: 0.017165, Validation Loss: 0.014844\nEpoch 164/300, Training Loss: 0.017622, Validation Loss: 0.015184\nEpoch 165/300, Training Loss: 0.017336, Validation Loss: 0.016582\nEpoch 166/300, Training Loss: 0.016638, Validation Loss: 0.011046\nEpoch 167/300, Training Loss: 0.017175, Validation Loss: 0.010362\nEpoch 168/300, Training Loss: 0.016372, Validation Loss: 0.008994\nEpoch 169/300, Training Loss: 0.016890, Validation Loss: 0.014883\nEpoch 170/300, Training Loss: 0.016700, Validation Loss: 0.011632\nEpoch 171/300, Training Loss: 0.015813, Validation Loss: 0.015512\nEpoch 172/300, Training Loss: 0.016131, Validation Loss: 0.012218\nEpoch 173/300, Training Loss: 0.016120, Validation Loss: 0.025908\nEpoch 174/300, Training Loss: 0.016325, Validation Loss: 0.010237\nEpoch 175/300, Training Loss: 0.016173, Validation Loss: 0.013783\nEpoch 176/300, Training Loss: 0.016327, Validation Loss: 0.009373\nEpoch 177/300, Training Loss: 0.016444, Validation Loss: 0.010280\nEpoch 178/300, Training Loss: 0.013652, Validation Loss: 0.008470\nEpoch 179/300, Training Loss: 0.013222, Validation Loss: 0.008513\nEpoch 180/300, Training Loss: 0.013159, Validation Loss: 0.009139\nEpoch 181/300, Training Loss: 0.013306, Validation Loss: 0.010033\nEpoch 182/300, Training Loss: 0.013125, Validation Loss: 0.009891\nEpoch 183/300, Training Loss: 0.013111, Validation Loss: 0.011471\nEpoch 184/300, Training Loss: 0.013071, Validation Loss: 0.009651\nEpoch 185/300, Training Loss: 0.013006, Validation Loss: 0.010665\nEpoch 186/300, Training Loss: 0.012926, Validation Loss: 0.011134\nEpoch 187/300, Training Loss: 0.012856, Validation Loss: 0.010419\nEpoch 188/300, Training Loss: 0.012754, Validation Loss: 0.009598\nEpoch 189/300, Training Loss: 0.012692, Validation Loss: 0.008029\nEpoch 190/300, Training Loss: 0.012732, Validation Loss: 0.010880\nEpoch 191/300, Training Loss: 0.012552, Validation Loss: 0.010754\nEpoch 192/300, Training Loss: 0.012495, Validation Loss: 0.011248\nEpoch 193/300, Training Loss: 0.012543, Validation Loss: 0.009253\nEpoch 194/300, Training Loss: 0.012441, Validation Loss: 0.008969\nEpoch 195/300, Training Loss: 0.012479, Validation Loss: 0.011120\nEpoch 196/300, Training Loss: 0.012394, Validation Loss: 0.010024\nEpoch 197/300, Training Loss: 0.012370, Validation Loss: 0.009048\nEpoch 198/300, Training Loss: 0.012442, Validation Loss: 0.011250\nEpoch 199/300, Training Loss: 0.012253, Validation Loss: 0.008048\nEpoch 200/300, Training Loss: 0.012186, Validation Loss: 0.007513\nEpoch 201/300, Training Loss: 0.012218, Validation Loss: 0.008509\nEpoch 202/300, Training Loss: 0.012183, Validation Loss: 0.008679\nEpoch 203/300, Training Loss: 0.012156, Validation Loss: 0.010360\nEpoch 204/300, Training Loss: 0.012031, Validation Loss: 0.011381\nEpoch 205/300, Training Loss: 0.012098, Validation Loss: 0.008184\nEpoch 206/300, Training Loss: 0.012044, Validation Loss: 0.008017\nEpoch 207/300, Training Loss: 0.011943, Validation Loss: 0.010056\nEpoch 208/300, Training Loss: 0.011874, Validation Loss: 0.011749\nEpoch 209/300, Training Loss: 0.011981, Validation Loss: 0.008682\nEpoch 210/300, Training Loss: 0.011904, Validation Loss: 0.009585\nEpoch 211/300, Training Loss: 0.011966, Validation Loss: 0.008445\nEpoch 212/300, Training Loss: 0.011970, Validation Loss: 0.012214\nEpoch 213/300, Training Loss: 0.011916, Validation Loss: 0.010302\nEpoch 214/300, Training Loss: 0.011791, Validation Loss: 0.008016\nEpoch 215/300, Training Loss: 0.011795, Validation Loss: 0.008827\nEpoch 216/300, Training Loss: 0.011834, Validation Loss: 0.011192\nEpoch 217/300, Training Loss: 0.011819, Validation Loss: 0.007524\nEpoch 218/300, Training Loss: 0.011798, Validation Loss: 0.010555\nEpoch 219/300, Training Loss: 0.011707, Validation Loss: 0.009458\nEpoch 220/300, Training Loss: 0.011852, Validation Loss: 0.010493\nEpoch 221/300, Training Loss: 0.011840, Validation Loss: 0.011720\nEpoch 222/300, Training Loss: 0.011702, Validation Loss: 0.010359\nEpoch 223/300, Training Loss: 0.011631, Validation Loss: 0.008729\nEpoch 224/300, Training Loss: 0.011621, Validation Loss: 0.009608\nEpoch 225/300, Training Loss: 0.011625, Validation Loss: 0.008824\nEpoch 226/300, Training Loss: 0.011626, Validation Loss: 0.008687\nEpoch 227/300, Training Loss: 0.011612, Validation Loss: 0.008115\nEpoch 228/300, Training Loss: 0.011569, Validation Loss: 0.009370\nEpoch 229/300, Training Loss: 0.011573, Validation Loss: 0.008555\nEpoch 230/300, Training Loss: 0.011548, Validation Loss: 0.011394\nEpoch 231/300, Training Loss: 0.011549, Validation Loss: 0.008044\nEpoch 232/300, Training Loss: 0.011553, Validation Loss: 0.009943\nEpoch 233/300, Training Loss: 0.011554, Validation Loss: 0.009915\nEpoch 234/300, Training Loss: 0.011520, Validation Loss: 0.007923\nEpoch 235/300, Training Loss: 0.011505, Validation Loss: 0.011636\nEpoch 236/300, Training Loss: 0.011472, Validation Loss: 0.011077\nEpoch 237/300, Training Loss: 0.011506, Validation Loss: 0.008225\nEpoch 238/300, Training Loss: 0.011537, Validation Loss: 0.009521\nEpoch 239/300, Training Loss: 0.011436, Validation Loss: 0.008085\nEpoch 240/300, Training Loss: 0.011376, Validation Loss: 0.011057\nEpoch 241/300, Training Loss: 0.011406, Validation Loss: 0.006971\nEpoch 242/300, Training Loss: 0.011416, Validation Loss: 0.007134\nEpoch 243/300, Training Loss: 0.011355, Validation Loss: 0.012808\nEpoch 244/300, Training Loss: 0.011363, Validation Loss: 0.008014\nEpoch 245/300, Training Loss: 0.011395, Validation Loss: 0.009854\nEpoch 246/300, Training Loss: 0.011386, Validation Loss: 0.009059\nEpoch 247/300, Training Loss: 0.011342, Validation Loss: 0.009876\nEpoch 248/300, Training Loss: 0.011264, Validation Loss: 0.008440\nEpoch 249/300, Training Loss: 0.011375, Validation Loss: 0.008292\nEpoch 250/300, Training Loss: 0.011109, Validation Loss: 0.012425\nEpoch 251/300, Training Loss: 0.011106, Validation Loss: 0.008662\nEpoch 252/300, Training Loss: 0.011292, Validation Loss: 0.010174\nEpoch 253/300, Training Loss: 0.011311, Validation Loss: 0.008664\nEpoch 254/300, Training Loss: 0.011136, Validation Loss: 0.011849\nEpoch 255/300, Training Loss: 0.011174, Validation Loss: 0.009819\nEpoch 256/300, Training Loss: 0.011264, Validation Loss: 0.009432\nEpoch 257/300, Training Loss: 0.011164, Validation Loss: 0.011298\nEpoch 258/300, Training Loss: 0.010208, Validation Loss: 0.007815\nEpoch 259/300, Training Loss: 0.010179, Validation Loss: 0.009082\nEpoch 260/300, Training Loss: 0.010145, Validation Loss: 0.010508\nEpoch 261/300, Training Loss: 0.010147, Validation Loss: 0.010089\nEpoch 262/300, Training Loss: 0.010155, Validation Loss: 0.009212\nEpoch 263/300, Training Loss: 0.010118, Validation Loss: 0.008167\nEpoch 264/300, Training Loss: 0.010112, Validation Loss: 0.007463\nEpoch 265/300, Training Loss: 0.010122, Validation Loss: 0.009604\nEpoch 266/300, Training Loss: 0.010122, Validation Loss: 0.009569\nEpoch 267/300, Training Loss: 0.010106, Validation Loss: 0.008729\nEpoch 268/300, Training Loss: 0.010094, Validation Loss: 0.010842\nEpoch 269/300, Training Loss: 0.010091, Validation Loss: 0.009012\nEpoch 270/300, Training Loss: 0.010154, Validation Loss: 0.009664\nEpoch 271/300, Training Loss: 0.010084, Validation Loss: 0.010065\nEpoch 272/300, Training Loss: 0.010090, Validation Loss: 0.009856\nEpoch 273/300, Training Loss: 0.010071, Validation Loss: 0.009160\nEpoch 274/300, Training Loss: 0.010107, Validation Loss: 0.008742\nEpoch 275/300, Training Loss: 0.010080, Validation Loss: 0.005962\nEpoch 276/300, Training Loss: 0.010051, Validation Loss: 0.010892\nEpoch 277/300, Training Loss: 0.010079, Validation Loss: 0.008806\nEpoch 278/300, Training Loss: 0.010087, Validation Loss: 0.008607\nEpoch 279/300, Training Loss: 0.010099, Validation Loss: 0.009384\nEpoch 280/300, Training Loss: 0.010055, Validation Loss: 0.010998\nEpoch 281/300, Training Loss: 0.010099, Validation Loss: 0.009109\nEpoch 282/300, Training Loss: 0.010064, Validation Loss: 0.011093\nEpoch 283/300, Training Loss: 0.009516, Validation Loss: 0.010841\nEpoch 284/300, Training Loss: 0.009520, Validation Loss: 0.007798\nEpoch 285/300, Training Loss: 0.009459, Validation Loss: 0.008416\nEpoch 286/300, Training Loss: 0.009467, Validation Loss: 0.009962\nEpoch 287/300, Training Loss: 0.009512, Validation Loss: 0.008215\nEpoch 288/300, Training Loss: 0.009502, Validation Loss: 0.010347\nEpoch 289/300, Training Loss: 0.009450, Validation Loss: 0.008237\nEpoch 290/300, Training Loss: 0.009510, Validation Loss: 0.006323\nEpoch 291/300, Training Loss: 0.009471, Validation Loss: 0.009513\nEpoch 292/300, Training Loss: 0.009455, Validation Loss: 0.010691\nEpoch 293/300, Training Loss: 0.009480, Validation Loss: 0.008795\nEpoch 294/300, Training Loss: 0.009474, Validation Loss: 0.007802\nEpoch 295/300, Training Loss: 0.009456, Validation Loss: 0.007830\nEpoch 296/300, Training Loss: 0.009187, Validation Loss: 0.007579\nEpoch 297/300, Training Loss: 0.009169, Validation Loss: 0.010169\nEpoch 298/300, Training Loss: 0.009147, Validation Loss: 0.009908\nEpoch 299/300, Training Loss: 0.009151, Validation Loss: 0.008861\nEpoch 300/300, Training Loss: 0.009135, Validation Loss: 0.007689\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# **Save the final model**","metadata":{}},{"cell_type":"code","source":"torch.save({\n        'model_state_dict': transformer_model.state_dict(),\n        'src_vocab': src_vocab,\n        'tgt_vocab': tgt_vocab,\n        'model_config': {\n            'input_vocab_size': input_vocab_size,\n            'output_vocab_size': output_vocab_size,\n            'model_dim': model_dim,\n            'num_heads': num_heads,\n            'num_layers': num_layers,\n            'hidden_dim': hidden_dim,\n            'max_len': max_len,\n            'dropout_rate': dropout_rate\n        }\n    }, 'transformer_ar_en_final.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T19:19:37.077425Z","iopub.execute_input":"2025-04-21T19:19:37.078136Z","iopub.status.idle":"2025-04-21T19:19:37.148581Z","shell.execute_reply.started":"2025-04-21T19:19:37.078118Z","shell.execute_reply":"2025-04-21T19:19:37.147710Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n\n# === Translation and BLEU scoring ===\ndef translate_sentence(sentence, src_vocab, tgt_vocab, model, max_len=100):\n    model.eval()\n    sentence = re.sub(r'[^\\w\\s]', '', sentence.lower())\n    tokens = ['<sos>'] + list(sentence) + ['<eos>']\n    input_ids = [src_vocab.get(tok, src_vocab['<unk>']) for tok in tokens]\n    src_tensor = torch.tensor(input_ids).unsqueeze(0).to(device)\n    tgt_ids = [tgt_vocab['<sos>']]\n    for _ in range(max_len):\n        tgt_tensor = torch.tensor(tgt_ids).unsqueeze(0).to(device)\n        with torch.no_grad():\n            output = model(src_tensor, tgt_tensor)\n        next_token = torch.argmax(output[0, -1, :]).item()\n        tgt_ids.append(next_token)\n        if next_token == tgt_vocab['<eos>']:\n            break\n    idx2word = {i: w for w, i in tgt_vocab.items()}\n    return ''.join([idx2word.get(i, '') for i in tgt_ids[1:] if i not in [0, tgt_vocab['<eos>']]])\n\ndef compute_bleu(model, dataloader, src_vocab, tgt_vocab, num_samples=100):\n    model.eval()\n    total_score = 0\n    count = 0\n    idx2src = {i: w for w, i in src_vocab.items()}\n    idx2tgt = {i: w for w, i in tgt_vocab.items()}\n    smoother = SmoothingFunction().method1\n    for src_batch, tgt_batch in dataloader:\n        src_batch, tgt_batch = src_batch.to(device), tgt_batch.to(device)\n        for src, tgt in zip(src_batch, tgt_batch):\n            src = [i for i in src.tolist() if i != 0]\n            tgt = [i for i in tgt.tolist() if i != 0 and i not in [tgt_vocab['<sos>'], tgt_vocab['<eos>']]]\n            src_sentence = ''.join([idx2src[i] for i in src])\n            ref = [''.join([idx2tgt[i] for i in tgt])]\n            pred = translate_sentence(src_sentence, src_vocab, tgt_vocab, model)\n            score = sentence_bleu([list(ref[0])], list(pred), smoothing_function=smoother)\n            total_score += score\n            count += 1\n            if count >= num_samples:\n                return total_score / count\n    return total_score / count","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T19:19:37.149575Z","iopub.execute_input":"2025-04-21T19:19:37.149875Z","iopub.status.idle":"2025-04-21T19:19:38.180290Z","shell.execute_reply.started":"2025-04-21T19:19:37.149849Z","shell.execute_reply":"2025-04-21T19:19:38.179757Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"def print_random_english_examples(model, src_vocab, tgt_vocab):\n    examples = [\n        \"What time is it?\",\n        \"I love programming.\",\n        \"This book is very interesting.\",\n        \"Can you help me, please?\",\n        \"The weather is nice today.\",\n        \"Hurry!, Tom\",\n        \"Stop,I'm sad\",\n        \"I am happy to see you again.\",\n        \"Tom is waiting for you at home.\",\n        \"Please come in and have a seat.\",\n        \"Let's go to the park this afternoon.\",\n        \"She loves to dance at parties.\",\n        \"He is a doctor and very kind.\",\n        \"I want to read more books this year.\",\n        \"The birds sing beautifully in the morning.\",\n        \"We need help to solve this problem.\",\n        \"You should try to be more creative.\"\n    ]\n    print(\"Random English Sentences with Translations:\")\n    for sentence in examples:\n        translation = translate_sentence(sentence, src_vocab, tgt_vocab, model)\n        print(f\"\\nExample Translation:\\nEN: {sentence}\\nAR: {translation}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T20:37:10.786331Z","iopub.execute_input":"2025-04-21T20:37:10.786712Z","iopub.status.idle":"2025-04-21T20:37:10.798743Z","shell.execute_reply.started":"2025-04-21T20:37:10.786685Z","shell.execute_reply":"2025-04-21T20:37:10.798038Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"\n# === Run and test BLEU after training ===\ndef run_test():\n    checkpoint = torch.load(\"transformer_ar_en_final.pt\", map_location=device)\n    config = checkpoint['model_config']\n    model = TransformerModel(\n        config['input_vocab_size'], config['output_vocab_size'],\n        config['model_dim'], config['num_heads'], config['num_layers'],\n        config['hidden_dim'], config['max_len'], config['dropout_rate']\n    ).to(device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    src_vocab = checkpoint['src_vocab']\n    tgt_vocab = checkpoint['tgt_vocab']\n\n    dataloader, _, _, _, _ = prepare_data(batch_size=32)\n\n    print(\"\\nTesting BLEU score on 1000 samples...\")\n    bleu = compute_bleu(model, dataloader, src_vocab, tgt_vocab, num_samples=1000)\n    print(f\"\\nAverage BLEU score: {bleu:.4f}\")\n\n    # Example translation\n    sentence = \"how are you\"\n    translation = translate_sentence(sentence, src_vocab, tgt_vocab, model)\n    print(f\"\\nExample Translation:\\nEN: {sentence}\\nAR: {translation}\")\n\n    print_random_english_examples(model, src_vocab, tgt_vocab)\n\n# Uncomment this to run test directly\nrun_test()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T20:37:10.803509Z","iopub.execute_input":"2025-04-21T20:37:10.803718Z","iopub.status.idle":"2025-04-21T20:37:10.893381Z","shell.execute_reply.started":"2025-04-21T20:37:10.803703Z","shell.execute_reply":"2025-04-21T20:37:10.892436Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/722182161.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Uncomment this to run test directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_31/722182161.py\u001b[0m in \u001b[0;36mrun_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# === Run and test BLEU after training ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transformer_ar_en_final.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     model = TransformerModel(\n","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"],"ename":"NameError","evalue":"name 'torch' is not defined","output_type":"error"}],"execution_count":2}]}